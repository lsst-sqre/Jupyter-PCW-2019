#+OPTIONS: toc:nil num:nil
#+REVEAL_ROOT: https://cdn.jsdelivr.net/reveal.js/3.0.0/
#+REVEAL_HLEVEL: 2
#+REVEAL_THEME: white
#+REVEAL_EXTRA_CSS: ./local.css
#+AUTHOR: Adam Thornton
#+EMAIL: athornton@lsst.org
#+TITLE: Tech Dive: Jupyter at LSST
#+DATE: 
* Links

[[https://github.com/lsst-sqre/Jupyter-PCW-2019.git][This talk]]: https://github.com/lsst-sqre/Jupyter-PCW-2019.git.

[[https://athornton.github.io/Jupyter-PCW-2019][This talk, rendered]]: https://athornton.github.io/Jupyter-PCW-2019.

The [[https://github.com/lsst-sqre/nublado.git][Notebook Aspect of the LSST Science Platform]]:
https://github.com/lsst-sqre/nublado.git (example sources).

* LSST
** Feeds and Speeds

[[https://www.lsst.org/scientists/keynumbers][This]] is the usual overview of what the LSST is going to be doing, and
how much of it there is.

** Notebook Environment (AKA "nublado")

This is the LSST Science Platform Interactive Notebook Component.
Basically, it's a way of letting scientists quickly iterate through
hypotheses looking for the ones interesting enough to burn a lot of
resources investigating.

My [[https://youtu.be/Xc0rUVznx1k?list=PL055Epbe6d5b572IRmYAHkUgcq3y6K3Ae][talk at JupyterCon 2018]] ([[https://athornton.github.io/JupyterCon-2018-talk][slides]]) is not a bad overview, if I do say
so myself.
* Fundamental assumptions

** Kubernetes is the right level of abstraction

You're free to argue with me about this.

If you do, you're wrong.

*** Containerization

Abstraction that lets you care about the application software rather
than the lower layers.

We're using Docker.

*** Composability

Kubernetes abstractions (e.g. the service) are designed such that we can
load-balance and (in some cases) get HA without having to work very hard
at it.  The deployment manages container lifecycles so we have the right
number of a given component running.  We don't have to manage the
(miserable) Docker-container-port-to-host-port mapping stuff ourselves.

This is where Kubernetes is magnificent.

*** Ubiquity

**** If you are not a data center service provider

Demand your service provider give you a Kubernetes interface.  The major
public clouds already do.


#+REVEAL: split

**** If you are a data center service provider

You either already do provide a managed Kubernetes service or you're
going to have to.  The longer you wait the more it will hurt.

Again, you can argue with me.  Again, you're wrong.

*** Orchestrateable

Kustomize, Terraform, Helm, or roll-your own.  Each of the first three
has advantages.

** JupyterHub

Why write your own spawner?  I haven't heard a convincing reason.

** JupyterLab

No sense in starting, several years from Science First Light, with
something that's already being supplanted.

You can still get the Classic Notebook view from it, if you have users
with notebooks that rely on things JupyterLab doesn't have extensions
for.  Encourage them to write those extensions or at least open issues.

* Jupyter Configuration

1. Authentication
2. Resource Control
3. Configuration
4. User Environments

** Authentication

*** Make it someone else's problem

It's full of corner cases and harder than it looks.

Are you *really* such a special snowflake that "users are members of
groups, and groups map to capabilities" won't work for you?

*** OAuth2 is nice

Wide support, good JupyterHub support, easy to add new providers.

[[https://github.com/lsst-sqre/nublado/blob/master/jupyterhub/sample_configs/10-authenticator.py][This]] is our configuration.

*** SSO

Custom header checking/injection in an Nginx ingress with a diversion
through OAuth2 flow, followed by passing around JWT.

Our [[https://github.com/lsst-sqre/nublado/blob/master/proxy/kubernetes/ingress.template.yml#L11][ingress annotations]] and [[https://github.com/lsst-sqre/nublado/blob/master/jupyterhub/sample_configs/10-authenticator.py#L315][header validation and parsing]].

*** Better SSO

CILogon+NCSA IDP supports association of identities, which is a nice
feature.  See if your OAuth2 provider can do it.

For instance, I'm usually signed into GitHub within ten minutes of
logging on somewhere.

** Resource Control

*** Group Membership

A group is really a mapping to a set of capabilities.

Any reasonable authentication provider should be able to also do
multiple group memberships for an identity.

*** Capabilities are equivalent to resource entitlement

What a user is allowed to do is the union of the capabilities of each of
their groups.

*** Namespace a user's resources in Kubernetes

**** Quotas

CPU, RAM, and object count.

Construct different quotas for different groups.

#+REVEAL: split

**** Ease of cleanup

Once you start constructing complex user environments, it's easy to
leak.

Namespace teardown removes all namespaced resources; in our experience,
everything but PVs.

*** Time is a resource

If you have a complex set of analysis tools, your images may be very
large.  Ours are 16GB now.

This can take a very long time to pull.

#+REVEAL: split

**** Prepuller

Run [[https://github.com/lsst-sqre/nublado/tree/master/prepuller][something]] to continually pull some set of versions of your standard
images.  Couple with a CI system and by the time people show up in the
morning, the new image is pulled.

Cuts startup time from 10 minutes to 15 seconds for us.

#+REVEAL: split

**** Build around your stack

Don't take a base JupyterLab and add your software to it if your
software is large.

Instead, add JupyterLab to your software.

*** Intermediate-scale parallelism

**** Things too big to fit in a single Python process/cell

Say, a handful of columns across a couple billion rows.
[[https://github.com/lsst-sqre/notebook-demo/blob/master/experiments/DASK-notebooks/gaia_all_sky.ipynb][(GAIA DR2, "l" and "b" columns only)]]

#+REVEAL: split

**** But not so big you want to go with full-on HTCondor yet

LSST DR11 final catalog size: 15PB.

#+REVEAL: split

**** We use Dask

By the end of the survey, much that we would now use a batch environment
for will be reasonable in an interactive Dask-like framework.  15PB of
catalog data?

#+REVEAL: split

**** Considerations for using Dask

***** Keeping Python libraries and versions synced

Use the same container with a [[https://github.com/lsst-sqre/nublado/blob/master/jupyterlab/runlab.sh#L135][different environmental flag]] set to say "be a
Dask worker, not a JupyterLab server."

In our environment, both Jupyter machinery and Dask machinery are small
compared to our analysis software.

#+REVEAL: split

***** Need additional Role/ServiceAccount/Rolebinding to allow Lab to spawn Dask

We populate a Dask worker yml document at each login that does the right
thing.  Modify at your own risk and you're still subject to quotas.

We anticipate very few users will ever need this level of control.

#+REVEAL: split

***** Resource limits can cause worker nodes to get reaped

Some attention to partitioning is still required.

**** Now the user Lab container has to create other containers

But in the same namespace, so quotas are still easy.

#+REVEAL: split

**** RBAC

It's not that scary.

[[https://github.com/lsst-sqre/nublado/tree/master/jupyterhub/kubernetes][This is an example]] for JupyterHub.

** Configuration

*** Modularity with ConfigMaps

This is a [[https://github.com/lsst-sqre/nublado/blob/master/jupyterhub/jupyterhub_config/jupyterhub_config.py][JupyterHub minimal configuration wrapper]] that loads the (sorted)
contents of a configuration directory.

This is [[https://github.com/lsst-sqre/nublado/blob/master/jupyterhub/sample_configs/30-environment.py][one of the files it loads.]]

Make your ConfigMaps generic.

*** Instance-specific values

Put them in templated environment, or in Secrets for sensitive data.

*** Don't be afraid to subclass right in your ConfigMaps

** User Environments

*** Use a spawner options form to present choices

+ Images
+ Container sizes
+ Mounted filesystems

You can use groups to control what's displayed.

*** Be the User

Pass information into the user container and do user setup as a
semiprivileged user with tightly controlled sudo.

Then start the JupyterLab server as the user, in the user's home
directory.

Do not give any sudo privileges to the user.

#+REVEAL: split

**** Complex environmental variables

Set up gid/groupname mappings, uid/username, and parse in the shell on
the far end...

This is what we've been doing, and we've found we need to...

***** base64-encode the really complicated stuff

[[https://github.com/lsst-sqre/nublado/blob/master/jupyterhub/sample_configs/20-spawner.py#L395][Here]] is how we do our initial Dask container template setup.

This gets silly fast.  Instead try:

#+REVEAL: split

**** ConfigMaps

Define ConfigMaps (which are namespaced) at spawn time and map them into
the user's Lab container as read-only files.

*** Persistent Storage

You just need a consistent and persistent way to assign uids/gids.

Your LDAP system should already do this.  GitHub has unique 32-bit
identifiers for users and groups.  Google will require you to map 64-bit
IDs to 32-bit.

#+REVEAL: split

**** Access Control is now a solved problem

You can use POSIX ACLs if there's something good old file permissions
can't handle.

#+REVEAL: split

**** NFS

Works, ubiquitous, _but_...

+ Performance
+ Locking
+ Non-default options in Kubernetes requires hacky workarounds

#+REVEAL: split

**** HostPath

"Get out of jail free."

+ Jails exist for reasons.
+ Not officially supported for ReadWriteMany.
+ GPFS seems to work for us, with good performance, but YMMV.

* Questions

[[https://github.com/lsst-sqre/Jupyter-PCW-2019.git][This talk]]: https://github.com/lsst-sqre/Jupyter-PCW-2019.git.

[[https://athornton.github.io/Jupyter-PCW-2019][This talk, rendered]]: https://athornton.github.io/Jupyter-PCW-2019.

The [[https://github.com/lsst-sqre/nublado.git][Notebook Aspect of the LSST Science Platform]]:
https://github.com/lsst-sqre/nublado.git (example sources).

Adam Thornton <athornton@lsst.org>

